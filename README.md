# Analyse & Pr√©vision de Donn√©es Industrielles

Projet personnel pr√™t pour GitHub : **mod√©lisation de s√©ries temporelles (ARIMA, LSTM)** et **d√©tection d‚Äôanomalies** pour des flux industriels (capteurs, production, consommation).

## ‚ú® Contenu
- **ARIMA (statsmodels)** pour la pr√©vision classique
- **LSTM (PyTorch)** pour la pr√©vision deep learning
- **D√©tection d'anomalies** (IsolationForest + z-score robuste)
- **Pipeline simple**: chargement ‚Üí pr√©traitement ‚Üí entra√Ænement ‚Üí √©valuation ‚Üí export
- **Donn√©es synth√©tiques** reproductibles (pour tester sans donn√©es priv√©es)
- **Scripts CLI** reproductibles + **config YAML**

## üìÅ Arborescence
```
industrial-forecasting-project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/            # Fichiers bruts (synthetic.csv fourni)
‚îÇ   ‚îî‚îÄ‚îÄ processed/      # Donn√©es nettoy√©es/features
‚îú‚îÄ‚îÄ models/             # Mod√®les entra√Æn√©s (.pkl/.pt)
‚îú‚îÄ‚îÄ notebooks/          # (Option) analyses exploratoires
‚îú‚îÄ‚îÄ scripts/            # Scripts CLI (train/eval/anomaly)
‚îú‚îÄ‚îÄ src/industrial_forecasting/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data.py
‚îÇ   ‚îú‚îÄ‚îÄ features.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arima.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lstm.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îî‚îÄ‚îÄ paths.py
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Makefile
‚îî‚îÄ‚îÄ README.md
```

## üöÄ D√©marrage rapide
```bash
# 1) Cr√©er l'environnement (ex. conda ou venv)
python -m venv .venv && source .venv/bin/activate  # (Linux/Mac)
#  Windows: .venv\Scripts\activate

# 2) Installer les d√©pendances
pip install -r requirements.txt

# 3) V√©rifier que les donn√©es synth√©tiques existent (d√©j√† incluses)
ls data/raw/real.csv

# 4) Entra√Æner ARIMA
python scripts/train_arima.py --config config.yaml

# 5) Entra√Æner LSTM (PyTorch)
python scripts/train_lstm.py --config config.yaml

# 6) D√©tecter les anomalies
python scripts/detect_anomalies.py --config config.yaml

# 7) √âvaluer les pr√©visions (ARIMA ou LSTM)
python scripts/evaluate_forecasts.py --config config.yaml --model arima
python scripts/evaluate_forecasts.py --config config.yaml --model lstm
```

## ‚öôÔ∏è Configuration (config.yaml)
- Chemins de fichiers, colonnes des donn√©es, fr√©quence temporelle
- Param√®tres ARIMA (p,d,q)
- Hyperparam√®tres LSTM (fen√™tre, hidden_size, lr, epochs)
- Param√®tres de d√©tection d‚Äôanomalies

## üß™ Donn√©es
Par d√©faut, **`data/raw/synthetic.csv`** contient un flux industriel synth√©tique (tendance + saisonnalit√© + bruit + anomalies inject√©es) pour tester l‚Äôend-to-end.

## üìù Licence
MIT ‚Äî libre d‚Äôutilisation √† des fins d‚Äôapprentissage et d√©monstration.


## üì¶ Jeux de donn√©es r√©els (Open)
- **SKAB (Skoltech Anomaly Benchmark)** ‚Äî capteurs industriels avec anomalies √©tiquet√©es. Script: `python scripts/fetch_skab.py` ‚Üí g√©n√®re `data/raw/skab_single.csv`.
- **NAB (Numenta Anomaly Benchmark)** ‚Äî plus de 50 s√©ries r√©elles/√©tiquet√©es. Script: `python scripts/fetch_nab.py` ‚Üí copies dans `data/raw/nab/`.

### Exemple d'usage (remplacer les chemins dans `config.yaml`)
```yaml
data:
  raw_path: "data/raw/skab_single.csv"
  datetime_col: "timestamp"
  value_col: "value"
  freq: "H"
  train_ratio: 0.8
```

## üì¶ Jeux de donn√©es r√©els (sans Kaggle)
- **NAB** (Numenta) ‚Äì anomalies r√©elles : `python scripts/fetch_data.py --dataset nab`
- **SKAB** (Skoltech) ‚Äì capteurs banc d‚Äôessai : `python scripts/fetch_data.py --dataset skab`
- **UCI SECOM** (semi-conducteurs) ‚Äì process industriel tabulaire : `python scripts/fetch_data.py --dataset secom`

> Les fichiers sont enregistr√©s comme `data/raw/real.csv` (colonnes `timestamp,value`). Mettez ensuite `data.raw_path: data/raw/real.csv` dans `config.yaml`.
